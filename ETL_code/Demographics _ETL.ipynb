{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c38106fd",
   "metadata": {},
   "source": [
    "# ETL to Retrieve Demographics Data from private API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac990a5",
   "metadata": {},
   "source": [
    "## Create unique list\n",
    "\n",
    "Testing process with 2018 and 2019 locations\n",
    "\n",
    "Will pull from the combined csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fdf04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b08803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.read_csv('../data_files/bls_metro_2019_clean.csv', header=0)\n",
    "df_2018 = pd.read_csv('../data_files/bls_metro_may2018_clean.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55c6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_title_2019 = df_2019[['area_title']]\n",
    "unique_area_title_2019 = area_title_2019['area_title'].unique()\n",
    "# unique_area_title_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403895cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_title_2018 = df_2018[['AREA_NAME']]\n",
    "unique_area_title_2018 = area_title_2018['AREA_NAME'].unique()\n",
    "# unique_area_title_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8129efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_2018_2019_area_names = [area_title_2019[['area_title']], area_title_2018[['AREA_NAME']]]\n",
    "# metro_2018_2019_area_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9c9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_list = [*unique_area_title_2019, *unique_area_title_2018]\n",
    "# joined_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509f543",
   "metadata": {},
   "source": [
    "### Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f2360dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['zipcode', 'state', 'city', 'population', 'race_asian', 'race_white', 'race_black', 'race_native', 'race_islander', 'race_other', 'race_two', 'race_hispanic', 'average_household_income'  ]\n",
    "df = pd.DataFrame(columns = columns)\n",
    "demographic_by_zipcode_df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91051812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup dict\n",
    "states = {\n",
    "    'AK': 'Alaska',\n",
    "    'AL': 'Alabama',\n",
    "    'AR': 'Arkansas',\n",
    "    'AZ': 'Arizona',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DC': 'District of Columbia',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'IA': 'Iowa',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MD': 'Maryland',\n",
    "    'ME': 'Maine',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MO': 'Missouri',\n",
    "    'MS': 'Mississippi',\n",
    "    'MT': 'Montana',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'NE': 'Nebraska',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NV': 'Nevada',\n",
    "    'NY': 'New York',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VA': 'Virginia',\n",
    "    'VT': 'Vermont',\n",
    "    'WA': 'Washington',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WV': 'West Virginia',\n",
    "    'WY': 'Wyoming'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f7a46",
   "metadata": {},
   "source": [
    "## Start request to private db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02d301b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentionally left out credentials\n",
    "# will update with config next commit\n",
    "from config import p\n",
    "import requests\n",
    "import mysql.connector\n",
    "servername = \"internal-db.s221289.gridserver.com\"\n",
    "username = \"db221289_stp\"\n",
    "password = p\n",
    "dbname = \"db221289_stp\"\n",
    "cnx = mysql.connector.connect(user=username, password=password,host=servername,database=dbname)\n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6558bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores any location with issues\n",
    "# will circle back to locations with multiple city/state concatenated\n",
    "location_issues_df = pd.DataFrame(columns=['city', 'state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c17d6ae",
   "metadata": {},
   "source": [
    "### Call to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1da72b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues with Allentown-Bethlehem-Easton, PA-NJ\n",
      "Issues with Augusta-Richmond County, GA-SC\n",
      "Issues with Cape Girardeau, MO-IL\n",
      "Issues with Charlotte-Concord-Gastonia, NC-SC\n",
      "Issues with Chattanooga, TN-GA\n",
      "Issues with Chicago-Naperville-Elgin, IL-IN-WI\n",
      "Issues with Cincinnati, OH-KY-IN\n",
      "Issues with Clarksville, TN-KY\n",
      "Issues with Columbus, GA-AL\n",
      "Issues with Cumberland, MD-WV\n",
      "Issues with Davenport-Moline-Rock Island, IA-IL\n",
      "Issues with Duluth, MN-WI\n",
      "Issues with Evansville, IN-KY\n",
      "Issues with Fargo, ND-MN\n",
      "Issues with Fayetteville-Springdale-Rogers, AR-MO\n",
      "Issues with Fort Smith, AR-OK\n",
      "Issues with Grand Forks, ND-MN\n",
      "Issues with Hagerstown-Martinsburg, MD-WV\n",
      "Issues with Huntington-Ashland, WV-KY-OH\n",
      "Issues with Kansas City, MO-KS\n",
      "Issues with Kingsport-Bristol-Bristol, TN-VA\n",
      "Issues with La Crosse-Onalaska, WI-MN\n",
      "Issues with Lewiston, ID-WA\n",
      "Issues with Logan, UT-ID\n",
      "Issues with Louisville/Jefferson County, KY-IN\n",
      "Issues with Memphis, TN-MS-AR\n",
      "Issues with Minneapolis-St. Paul-Bloomington, MN-WI\n",
      "Issues with Myrtle Beach-Conway-North Myrtle Beach, SC-NC\n",
      "Issues with New York-Newark-Jersey City, NY-NJ-PA\n",
      "Issues with Omaha-Council Bluffs, NE-IA\n",
      "Issues with Philadelphia-Camden-Wilmington, PA-NJ-DE-MD\n",
      "Issues with Portland-Vancouver-Hillsboro, OR-WA\n",
      "Issues with St. Joseph, MO-KS\n",
      "Issues with St. Louis, MO-IL\n",
      "Issues with Salisbury, MD-DE\n",
      "Issues with Sioux City, IA-NE-SD\n",
      "Issues with South Bend-Mishawaka, IN-MI\n",
      "Issues with Texarkana, TX-AR\n",
      "Issues with Virginia Beach-Norfolk-Newport News, VA-NC\n",
      "Issues with Washington-Arlington-Alexandria, DC-VA-MD-WV\n",
      "Issues with Weirton-Steubenville, WV-OH\n",
      "Issues with Wheeling, WV-OH\n",
      "Issues with Winchester, VA-WV\n",
      "Issues with Youngstown-Warren-Boardman, OH-PA\n",
      "Issues with Boston-Cambridge-Nashua, MA-NH\n",
      "Issues with Dover-Durham, NH-ME\n",
      "Issues with Norwich-New London-Westerly, CT-RI\n",
      "Issues with Portsmouth, NH-ME\n",
      "Issues with Providence-Warwick, RI-MA\n",
      "Issues with Springfield, MA-CT\n",
      "Issues with Worcester, MA-CT\n",
      "Issues with Fayetteville-Springdale-Rogers, AR-MO\n",
      "Issues with Fort Smith, AR-OK\n",
      "Issues with Norwich-New London-Westerly, CT-RI\n",
      "Issues with Washington-Arlington-Alexandria, DC-VA-MD-WV\n",
      "Issues with Augusta-Richmond County, GA-SC\n",
      "Issues with Columbus, GA-AL\n",
      "Issues with Davenport-Moline-Rock Island, IA-IL\n",
      "Issues with Sioux City, IA-NE-SD\n",
      "Issues with Lewiston, ID-WA\n",
      "Issues with Chicago-Naperville-Elgin, IL-IN-WI\n",
      "Issues with Evansville, IN-KY\n",
      "Issues with South Bend-Mishawaka, IN-MI\n",
      "Issues with Louisville/Jefferson County, KY-IN\n",
      "Issues with Boston-Cambridge-Nashua, MA-NH\n",
      "Issues with Springfield, MA-CT\n",
      "Issues with Worcester, MA-CT\n",
      "Issues with Cumberland, MD-WV\n",
      "Issues with Hagerstown-Martinsburg, MD-WV\n",
      "Issues with Salisbury, MD-DE\n",
      "Issues with Duluth, MN-WI\n",
      "Issues with Minneapolis-St. Paul-Bloomington, MN-WI\n",
      "Issues with Cape Girardeau, MO-IL\n",
      "Issues with Kansas City, MO-KS\n",
      "Issues with St. Joseph, MO-KS\n",
      "Issues with St. Louis, MO-IL\n",
      "Issues with Charlotte-Concord-Gastonia, NC-SC\n",
      "Issues with Fargo, ND-MN\n",
      "Issues with Grand Forks, ND-MN\n",
      "Issues with Omaha-Council Bluffs, NE-IA\n",
      "Issues with Dover-Durham, NH-ME\n",
      "Issues with Portsmouth, NH-ME\n",
      "Issues with New York-Newark-Jersey City, NY-NJ-PA\n",
      "Issues with Cincinnati, OH-KY-IN\n",
      "Issues with Youngstown-Warren-Boardman, OH-PA\n",
      "Issues with Portland-Vancouver-Hillsboro, OR-WA\n",
      "Issues with Allentown-Bethlehem-Easton, PA-NJ\n",
      "Issues with Philadelphia-Camden-Wilmington, PA-NJ-DE-MD\n",
      "Issues with Providence-Warwick, RI-MA\n",
      "Issues with Myrtle Beach-Conway-North Myrtle Beach, SC-NC\n",
      "Issues with Chattanooga, TN-GA\n",
      "Issues with Clarksville, TN-KY\n",
      "Issues with Kingsport-Bristol-Bristol, TN-VA\n",
      "Issues with Memphis, TN-MS-AR\n",
      "Issues with Texarkana, TX-AR\n",
      "Issues with Logan, UT-ID\n",
      "Issues with Virginia Beach-Norfolk-Newport News, VA-NC\n",
      "Issues with Winchester, VA-WV\n",
      "Issues with La Crosse-Onalaska, WI-MN\n",
      "Issues with Huntington-Ashland, WV-KY-OH\n",
      "Issues with Weirton-Steubenville, WV-OH\n",
      "Issues with Wheeling, WV-OH\n"
     ]
    }
   ],
   "source": [
    "def requestDemographicForCityState(_city, _state):\n",
    "    # check if this state exists (seeing some strange state abbrs)\n",
    "    if _state.upper() in states :\n",
    "        search_state =  states[_state.upper()].upper()\n",
    "        search_city =  _city.upper().replace(\"'\", \"''\")\n",
    "        query = (f\"SELECT zip_zcta, state_name, city_name, age_total as population, race_and_ethnicity_asian, race_and_ethnicity_white, race_and_ethnicity_black, race_and_ethnicity_native, race_and_ethnicity_islander, race_and_ethnicity_other, race_and_ethnicity_two, race_and_ethnicity_hispanic, average_household_income FROM `zipcodeDemographic` WHERE state_name = '{search_state}' and city_name = '{search_city}' \")\n",
    "        cursor.execute(query)\n",
    "        # iterate throw rows and add to df\n",
    "        for (zipcode) in cursor:\n",
    "            demographic_by_zipcode_df.loc[len(demographic_by_zipcode_df.index)] = zipcode\n",
    "    \n",
    "# iterate through locations list\n",
    "for location in joined_list:\n",
    "    locationParts = location.split(', ')\n",
    "    locationStateParts = locationParts[1].split('-')\n",
    "    # temp check to make sure the stateParts array only contain 1 value\n",
    "    # if state array is more than 1 value then add to location_issues_df for later parsing\n",
    "    if len(locationStateParts) > 1:\n",
    "        print (f\"Issues with {location}\")\n",
    "        location_issues_df.loc[len(location_issues_df.index)] = [locationParts[0], locationParts[1]]\n",
    "    # else lets make that request\n",
    "    else:\n",
    "        city = locationParts[0]\n",
    "        state = locationParts[1]\n",
    "        requestDemographicForCityState(city, state)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9801fbd",
   "metadata": {},
   "source": [
    "### Demographic by zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11fff85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>population</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_native</th>\n",
       "      <th>race_islander</th>\n",
       "      <th>race_other</th>\n",
       "      <th>race_two</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>average_household_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79601</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>28041</td>\n",
       "      <td>546</td>\n",
       "      <td>15155</td>\n",
       "      <td>3887</td>\n",
       "      <td>352</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>693</td>\n",
       "      <td>7323</td>\n",
       "      <td>52921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79605</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>29672</td>\n",
       "      <td>569</td>\n",
       "      <td>19773</td>\n",
       "      <td>2168</td>\n",
       "      <td>150</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "      <td>467</td>\n",
       "      <td>6421</td>\n",
       "      <td>63713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79606</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>23929</td>\n",
       "      <td>988</td>\n",
       "      <td>16483</td>\n",
       "      <td>1959</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>512</td>\n",
       "      <td>3959</td>\n",
       "      <td>77331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79607</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>3309</td>\n",
       "      <td>150</td>\n",
       "      <td>1890</td>\n",
       "      <td>561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>520</td>\n",
       "      <td>53954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79699</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>53715</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Madison</td>\n",
       "      <td>14246</td>\n",
       "      <td>1697</td>\n",
       "      <td>10474</td>\n",
       "      <td>505</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>445</td>\n",
       "      <td>1102</td>\n",
       "      <td>48375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>53726</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Madison</td>\n",
       "      <td>5869</td>\n",
       "      <td>716</td>\n",
       "      <td>4592</td>\n",
       "      <td>194</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>239</td>\n",
       "      <td>85599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>25301</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>2360</td>\n",
       "      <td>48</td>\n",
       "      <td>1601</td>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>156</td>\n",
       "      <td>65</td>\n",
       "      <td>51371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>25304</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>8307</td>\n",
       "      <td>297</td>\n",
       "      <td>6800</td>\n",
       "      <td>921</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "      <td>143</td>\n",
       "      <td>92942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>25305</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1696 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     zipcode          state        city population race_asian race_white  \\\n",
       "0      79601          Texas     Abilene      28041        546      15155   \n",
       "1      79605          Texas     Abilene      29672        569      19773   \n",
       "2      79606          Texas     Abilene      23929        988      16483   \n",
       "3      79607          Texas     Abilene       3309        150       1890   \n",
       "4      79699          Texas     Abilene        124          0         84   \n",
       "...      ...            ...         ...        ...        ...        ...   \n",
       "1691   53715      Wisconsin     Madison      14246       1697      10474   \n",
       "1692   53726      Wisconsin     Madison       5869        716       4592   \n",
       "1693   25301  West Virginia  Charleston       2360         48       1601   \n",
       "1694   25304  West Virginia  Charleston       8307        297       6800   \n",
       "1695   25305  West Virginia  Charleston          0          0          0   \n",
       "\n",
       "     race_black race_native race_islander race_other race_two race_hispanic  \\\n",
       "0          3887         352             2         83      693          7323   \n",
       "1          2168         150            13        111      467          6421   \n",
       "2          1959          22             0          6      512          3959   \n",
       "3           561           0             0          0      188           520   \n",
       "4            22           0             0          0        0            18   \n",
       "...         ...         ...           ...        ...      ...           ...   \n",
       "1691        505          16             0          7      445          1102   \n",
       "1692        194          27             0          0      101           239   \n",
       "1693        452           0             0         38      156            65   \n",
       "1694        921           4             0         15      127           143   \n",
       "1695          0           0             0          0        0             0   \n",
       "\n",
       "     average_household_income  \n",
       "0                       52921  \n",
       "1                       63713  \n",
       "2                       77331  \n",
       "3                       53954  \n",
       "4                          -1  \n",
       "...                       ...  \n",
       "1691                    48375  \n",
       "1692                    85599  \n",
       "1693                    51371  \n",
       "1694                    92942  \n",
       "1695                       -1  \n",
       "\n",
       "[1696 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_by_zipcode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48dac0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demograhpics by zipcode to csv\n",
    "demographic_by_zipcode_df.to_csv('../data_files/metro_demographic_by_zipcode.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "610159c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zipcode                     object\n",
       "state                       object\n",
       "city                        object\n",
       "population                  object\n",
       "race_asian                  object\n",
       "race_white                  object\n",
       "race_black                  object\n",
       "race_native                 object\n",
       "race_islander               object\n",
       "race_other                  object\n",
       "race_two                    object\n",
       "race_hispanic               object\n",
       "average_household_income    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_by_zipcode_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd5bc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert objects to int\n",
    "convert_columns = ['population', 'race_asian', 'race_white', 'race_black', 'race_native', 'race_islander', 'race_other', 'race_two', 'race_hispanic', 'average_household_income']\n",
    "demographic_by_zipcode_df[convert_columns] = demographic_by_zipcode_df[convert_columns].astype(str).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da27f2a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zipcode                     object\n",
       "state                       object\n",
       "city                        object\n",
       "population                   int64\n",
       "race_asian                   int64\n",
       "race_white                   int64\n",
       "race_black                   int64\n",
       "race_native                  int64\n",
       "race_islander                int64\n",
       "race_other                   int64\n",
       "race_two                     int64\n",
       "race_hispanic                int64\n",
       "average_household_income     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_by_zipcode_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948c7e8",
   "metadata": {},
   "source": [
    "### Demographic grouped by City and State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6585485d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_native</th>\n",
       "      <th>race_islander</th>\n",
       "      <th>race_two</th>\n",
       "      <th>race_other</th>\n",
       "      <th>average_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>170150</td>\n",
       "      <td>4506</td>\n",
       "      <td>106770</td>\n",
       "      <td>17194</td>\n",
       "      <td>36482</td>\n",
       "      <td>1048</td>\n",
       "      <td>30</td>\n",
       "      <td>3720</td>\n",
       "      <td>400</td>\n",
       "      <td>49583.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akron</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>189788</td>\n",
       "      <td>4328</td>\n",
       "      <td>108980</td>\n",
       "      <td>62986</td>\n",
       "      <td>3522</td>\n",
       "      <td>268</td>\n",
       "      <td>44</td>\n",
       "      <td>9530</td>\n",
       "      <td>130</td>\n",
       "      <td>42943.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>129768</td>\n",
       "      <td>1896</td>\n",
       "      <td>41370</td>\n",
       "      <td>80200</td>\n",
       "      <td>3474</td>\n",
       "      <td>192</td>\n",
       "      <td>48</td>\n",
       "      <td>2482</td>\n",
       "      <td>106</td>\n",
       "      <td>59234.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>639982</td>\n",
       "      <td>16874</td>\n",
       "      <td>307760</td>\n",
       "      <td>19090</td>\n",
       "      <td>252998</td>\n",
       "      <td>27212</td>\n",
       "      <td>426</td>\n",
       "      <td>13590</td>\n",
       "      <td>2032</td>\n",
       "      <td>61589.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>118368</td>\n",
       "      <td>3712</td>\n",
       "      <td>47766</td>\n",
       "      <td>61566</td>\n",
       "      <td>2988</td>\n",
       "      <td>412</td>\n",
       "      <td>14</td>\n",
       "      <td>1848</td>\n",
       "      <td>62</td>\n",
       "      <td>57892.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>383468</td>\n",
       "      <td>10252</td>\n",
       "      <td>249662</td>\n",
       "      <td>35804</td>\n",
       "      <td>70972</td>\n",
       "      <td>2370</td>\n",
       "      <td>72</td>\n",
       "      <td>14130</td>\n",
       "      <td>206</td>\n",
       "      <td>70005.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Wichita Falls</td>\n",
       "      <td>Texas</td>\n",
       "      <td>131792</td>\n",
       "      <td>1926</td>\n",
       "      <td>75816</td>\n",
       "      <td>16896</td>\n",
       "      <td>32308</td>\n",
       "      <td>806</td>\n",
       "      <td>52</td>\n",
       "      <td>3360</td>\n",
       "      <td>628</td>\n",
       "      <td>56167.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Winston-Salem</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>66164</td>\n",
       "      <td>2702</td>\n",
       "      <td>45852</td>\n",
       "      <td>11472</td>\n",
       "      <td>4198</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1692</td>\n",
       "      <td>134</td>\n",
       "      <td>34263.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Yakima</td>\n",
       "      <td>Washington</td>\n",
       "      <td>92516</td>\n",
       "      <td>570</td>\n",
       "      <td>41438</td>\n",
       "      <td>680</td>\n",
       "      <td>46548</td>\n",
       "      <td>988</td>\n",
       "      <td>20</td>\n",
       "      <td>2190</td>\n",
       "      <td>82</td>\n",
       "      <td>52787.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Yuba City</td>\n",
       "      <td>California</td>\n",
       "      <td>81918</td>\n",
       "      <td>7784</td>\n",
       "      <td>38672</td>\n",
       "      <td>1748</td>\n",
       "      <td>29664</td>\n",
       "      <td>516</td>\n",
       "      <td>390</td>\n",
       "      <td>3008</td>\n",
       "      <td>136</td>\n",
       "      <td>60353.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              city           state  population  race_asian  race_white  \\\n",
       "0          Abilene           Texas      170150        4506      106770   \n",
       "1            Akron            Ohio      189788        4328      108980   \n",
       "2           Albany         Georgia      129768        1896       41370   \n",
       "3      Albuquerque      New Mexico      639982       16874      307760   \n",
       "4       Alexandria       Louisiana      118368        3712       47766   \n",
       "..             ...             ...         ...         ...         ...   \n",
       "150        Wichita          Kansas      383468       10252      249662   \n",
       "151  Wichita Falls           Texas      131792        1926       75816   \n",
       "152  Winston-Salem  North Carolina       66164        2702       45852   \n",
       "153         Yakima      Washington       92516         570       41438   \n",
       "154      Yuba City      California       81918        7784       38672   \n",
       "\n",
       "     race_black  race_hispanic  race_native  race_islander  race_two  \\\n",
       "0         17194          36482         1048             30      3720   \n",
       "1         62986           3522          268             44      9530   \n",
       "2         80200           3474          192             48      2482   \n",
       "3         19090         252998        27212            426     13590   \n",
       "4         61566           2988          412             14      1848   \n",
       "..          ...            ...          ...            ...       ...   \n",
       "150       35804          70972         2370             72     14130   \n",
       "151       16896          32308          806             52      3360   \n",
       "152       11472           4198          114              0      1692   \n",
       "153         680          46548          988             20      2190   \n",
       "154        1748          29664          516            390      3008   \n",
       "\n",
       "     race_other  average_income  \n",
       "0           400    49583.600000  \n",
       "1           130    42943.888889  \n",
       "2           106    59234.666667  \n",
       "3          2032    61589.000000  \n",
       "4            62    57892.333333  \n",
       "..          ...             ...  \n",
       "150         206    70005.857143  \n",
       "151         628    56167.200000  \n",
       "152         134    34263.333333  \n",
       "153          82    52787.000000  \n",
       "154         136    60353.000000  \n",
       "\n",
       "[155 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_demographic = demographic_by_zipcode_df.groupby(['city', 'state'], as_index=False).agg(\n",
    "    population = ('population', 'sum'),\n",
    "    race_asian = ('race_asian', 'sum'),\n",
    "    race_white = ('race_white', 'sum'),\n",
    "    race_black = ('race_black', 'sum'),\n",
    "    race_hispanic = ('race_hispanic', 'sum'),\n",
    "    race_native = ('race_native', 'sum'),\n",
    "    race_islander = ('race_islander', 'sum'),\n",
    "    race_two = ('race_two', 'sum'),\n",
    "    race_other = ('race_other', 'sum'),\n",
    "    average_income = ('average_household_income', 'mean'))\n",
    "grouped_demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2648e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "grouped_demographic.to_csv('../data_files/metro_demographic_by_city_state.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df2e9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shut it down\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d310a9",
   "metadata": {},
   "source": [
    "#### Need to untangle the locations with multiple city and state\n",
    "\n",
    "These locations are formatted by their metropolitan area name. Some are just the city, while others are made up of several cities. We should keep these locations together and all locations involved should be represented as a singular metropolitan area.\n",
    "Need to \n",
    "1. parse into list\n",
    "2. request each\n",
    "3. add to temp df \n",
    "4. add to zipcodes df\n",
    "5. groupby, sum(), mean() back together\n",
    "4. add into groups df\n",
    "\n",
    "Allentown-Bethlehem-Easton, PA-NJ\n",
    "Wikipedia defines this as: The Lehigh Valley's principal cities are Allentown, Bethlehem and Easton, making up the Allentown–Bethlehem–Easton metropolitan area.\n",
    "\n",
    "Philadelphia-Camden-Wilmington, PA-NJ-DE-MD\n",
    "\n",
    "Can parse out to:\n",
    "\n",
    "- Philadelphia PA\n",
    "- Camden NJ\n",
    "- Wilmington DE\n",
    "- ??? MD \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b10bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
